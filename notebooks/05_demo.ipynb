{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 05 demo\n",
    "\n",
    "**in**: rendered videos from 03_overlay  \n",
    "**out**: demo clips ready for presentation\n",
    "\n",
    "this notebook identifies best moments, cuts highlights, and prepares the final demo package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 1: identify best moments (eval swings, goals)\n",
    "\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUT_DIR = Path('../data/out')\n",
    "RENDER_DIR = Path('../data/render')\n",
    "DEMO_DIR = RENDER_DIR / 'demo'\n",
    "DEMO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# find eval files\n",
    "eval_files = list(OUT_DIR.glob('*_eval_ts.csv'))\n",
    "if not eval_files:\n",
    "    raise FileNotFoundError('no eval_ts.csv found - run 02_eval_bar first')\n",
    "\n",
    "EVAL_CSV = eval_files[0]\n",
    "MATCH_NAME = EVAL_CSV.stem.replace('_eval_ts', '')\n",
    "print(f'analyzing: {MATCH_NAME}')\n",
    "\n",
    "eval_df = pd.read_csv(EVAL_CSV)\n",
    "print(f'loaded {len(eval_df)} frames')\n",
    "\n",
    "# compute eval changes\n",
    "eval_df['eval_change'] = eval_df['eval_bar'].diff().abs()\n",
    "eval_df['eval_smooth_change'] = eval_df['eval_bar'].rolling(10).mean().diff().abs()\n",
    "\n",
    "# find biggest swings\n",
    "eval_df['is_swing'] = eval_df['eval_smooth_change'] > eval_df['eval_smooth_change'].quantile(0.95)\n",
    "\n",
    "# cluster swings that are close together\n",
    "swing_frames = eval_df[eval_df['is_swing']]['frame'].values\n",
    "swing_times = eval_df[eval_df['is_swing']]['t_sec'].values\n",
    "\n",
    "moments = []\n",
    "if len(swing_times) > 0:\n",
    "    cluster_gap = 10  # seconds\n",
    "    current_start = swing_times[0]\n",
    "    current_end = swing_times[0]\n",
    "    \n",
    "    for t in swing_times[1:]:\n",
    "        if t - current_end < cluster_gap:\n",
    "            current_end = t\n",
    "        else:\n",
    "            moments.append({\n",
    "                'start': max(0, current_start - 5),\n",
    "                'end': current_end + 5,\n",
    "                'duration': current_end - current_start + 10,\n",
    "            })\n",
    "            current_start = t\n",
    "            current_end = t\n",
    "    \n",
    "    moments.append({\n",
    "        'start': max(0, current_start - 5),\n",
    "        'end': current_end + 5,\n",
    "        'duration': current_end - current_start + 10,\n",
    "    })\n",
    "\n",
    "# rank by eval variance in window\n",
    "for m in moments:\n",
    "    window_df = eval_df[(eval_df['t_sec'] >= m['start']) & (eval_df['t_sec'] <= m['end'])]\n",
    "    m['eval_var'] = window_df['eval_bar'].var()\n",
    "    m['eval_range'] = window_df['eval_bar'].max() - window_df['eval_bar'].min()\n",
    "\n",
    "moments = sorted(moments, key=lambda x: x['eval_range'], reverse=True)\n",
    "\n",
    "print(f'\\nfound {len(moments)} interesting moments:')\n",
    "for i, m in enumerate(moments[:10]):\n",
    "    print(f\"  {i+1}. {m['start']:.0f}s - {m['end']:.0f}s (range: {m['eval_range']:.1f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2: cut 30-60s highlight clips\n",
    "\n",
    "FINAL_VIDEO = RENDER_DIR / f'{MATCH_NAME}_final.mp4'\n",
    "if not FINAL_VIDEO.exists():\n",
    "    # fallback to overlay video\n",
    "    FINAL_VIDEO = RENDER_DIR / f'{MATCH_NAME}_overlay.mp4'\n",
    "\n",
    "if not FINAL_VIDEO.exists():\n",
    "    print(f'ERROR: no rendered video found at {FINAL_VIDEO}')\n",
    "    print('run 03_overlay first')\n",
    "else:\n",
    "    print(f'source video: {FINAL_VIDEO}')\n",
    "\n",
    "\n",
    "def cut_clip(input_path, output_path, start_sec, duration_sec):\n",
    "    \"\"\"Cut a clip from video using ffmpeg.\"\"\"\n",
    "    cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-ss', str(start_sec),\n",
    "        '-i', str(input_path),\n",
    "        '-t', str(duration_sec),\n",
    "        '-c:v', 'libx264',\n",
    "        '-preset', 'fast',\n",
    "        '-crf', '22',\n",
    "        '-pix_fmt', 'yuv420p',\n",
    "        str(output_path)\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    return result.returncode == 0\n",
    "\n",
    "\n",
    "# cut top 5 highlight clips\n",
    "clip_count = min(5, len(moments))\n",
    "clips = []\n",
    "\n",
    "for i in range(clip_count):\n",
    "    m = moments[i]\n",
    "    \n",
    "    # target 30-60 seconds\n",
    "    duration = min(60, max(30, m['duration']))\n",
    "    start = m['start']\n",
    "    \n",
    "    clip_path = DEMO_DIR / f'{MATCH_NAME}_highlight_{i+1:02d}.mp4'\n",
    "    \n",
    "    if FINAL_VIDEO.exists():\n",
    "        success = cut_clip(FINAL_VIDEO, clip_path, start, duration)\n",
    "        if success:\n",
    "            clips.append({\n",
    "                'path': clip_path,\n",
    "                'start': start,\n",
    "                'duration': duration,\n",
    "                'eval_range': m['eval_range'],\n",
    "            })\n",
    "            print(f'cut clip {i+1}: {clip_path.name} ({start:.0f}s, {duration:.0f}s)')\n",
    "        else:\n",
    "            print(f'failed to cut clip {i+1}')\n",
    "\n",
    "print(f'\\ngenerated {len(clips)} highlight clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 3: add title cards / annotations\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "def add_title_card(video_path, title_text, duration_sec=3):\n",
    "    \"\"\"\n",
    "    Prepend a title card to a video.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(str(video_path))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    \n",
    "    # temp file for title card\n",
    "    title_path = video_path.parent / f'{video_path.stem}_title.mp4'\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(str(title_path), fourcc, fps, (width, height))\n",
    "    \n",
    "    # create title frames\n",
    "    for _ in range(int(fps * duration_sec)):\n",
    "        frame = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        frame[:] = (30, 30, 30)  # dark gray\n",
    "        \n",
    "        # add text\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "        font_scale = 1.5\n",
    "        thickness = 3\n",
    "        \n",
    "        text_size = cv2.getTextSize(title_text, font, font_scale, thickness)[0]\n",
    "        text_x = (width - text_size[0]) // 2\n",
    "        text_y = (height + text_size[1]) // 2\n",
    "        \n",
    "        cv2.putText(frame, title_text, (text_x, text_y), font, font_scale, \n",
    "                    (255, 255, 255), thickness)\n",
    "        \n",
    "        writer.write(frame)\n",
    "    \n",
    "    writer.release()\n",
    "    cap.release()\n",
    "    \n",
    "    return title_path\n",
    "\n",
    "\n",
    "def concat_videos(video_paths, output_path):\n",
    "    \"\"\"Concatenate multiple videos using ffmpeg.\"\"\"\n",
    "    # create concat file\n",
    "    concat_file = output_path.parent / 'concat.txt'\n",
    "    with open(concat_file, 'w') as f:\n",
    "        for p in video_paths:\n",
    "            f.write(f\"file '{p}'\\n\")\n",
    "    \n",
    "    cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-f', 'concat',\n",
    "        '-safe', '0',\n",
    "        '-i', str(concat_file),\n",
    "        '-c:v', 'libx264',\n",
    "        '-preset', 'fast',\n",
    "        '-crf', '22',\n",
    "        str(output_path)\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    concat_file.unlink()  # cleanup\n",
    "    return result.returncode == 0\n",
    "\n",
    "\n",
    "# add title cards to clips\n",
    "titled_clips = []\n",
    "\n",
    "for i, clip in enumerate(clips):\n",
    "    title = f\"Highlight {i+1} - Eval Range: {clip['eval_range']:.0f}\"\n",
    "    \n",
    "    # create title card\n",
    "    title_path = add_title_card(clip['path'], title, duration_sec=2)\n",
    "    \n",
    "    # concat title + clip\n",
    "    titled_path = DEMO_DIR / f'{MATCH_NAME}_titled_{i+1:02d}.mp4'\n",
    "    \n",
    "    if concat_videos([title_path, clip['path']], titled_path):\n",
    "        titled_clips.append(titled_path)\n",
    "        print(f'titled clip: {titled_path.name}')\n",
    "    \n",
    "    # cleanup title card\n",
    "    title_path.unlink(missing_ok=True)\n",
    "\n",
    "print(f'\\ncreated {len(titled_clips)} titled clips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4: export final demo package\n",
    "\n",
    "# create combined demo reel\n",
    "DEMO_REEL = DEMO_DIR / f'{MATCH_NAME}_demo_reel.mp4'\n",
    "\n",
    "if len(titled_clips) > 0:\n",
    "    # add intro title\n",
    "    intro_frame = np.zeros((720, 1280, 3), dtype=np.uint8)\n",
    "    intro_frame[:] = (20, 20, 20)\n",
    "    \n",
    "    intro_path = DEMO_DIR / 'intro.mp4'\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    writer = cv2.VideoWriter(str(intro_path), fourcc, 25, (1280, 720))\n",
    "    \n",
    "    for _ in range(100):  # 4 seconds\n",
    "        frame = intro_frame.copy()\n",
    "        \n",
    "        # title\n",
    "        cv2.putText(frame, 'BOTTLEJOB DETECTOR', (280, 300), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 4)\n",
    "        cv2.putText(frame, 'Soccer Analytics Demo', (400, 380), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (150, 150, 150), 2)\n",
    "        cv2.putText(frame, f'Match: {MATCH_NAME}', (480, 450), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (100, 100, 100), 2)\n",
    "        \n",
    "        writer.write(frame)\n",
    "    \n",
    "    writer.release()\n",
    "    \n",
    "    # concat all\n",
    "    all_clips = [intro_path] + titled_clips\n",
    "    \n",
    "    if concat_videos(all_clips, DEMO_REEL):\n",
    "        print(f'demo reel created: {DEMO_REEL}')\n",
    "    else:\n",
    "        print('failed to create demo reel')\n",
    "    \n",
    "    # cleanup intro\n",
    "    intro_path.unlink(missing_ok=True)\n",
    "else:\n",
    "    print('no clips to combine into demo reel')\n",
    "\n",
    "# summary\n",
    "print('\\n' + '='*60)\n",
    "print('DEMO PACKAGE SUMMARY')\n",
    "print('='*60)\n",
    "print(f'match: {MATCH_NAME}')\n",
    "print(f'clips: {len(clips)}')\n",
    "print(f'demo reel: {DEMO_REEL if DEMO_REEL.exists() else \"not created\"}')\n",
    "print('\\nfiles:')\n",
    "for f in sorted(DEMO_DIR.glob('*.mp4')):\n",
    "    size_mb = f.stat().st_size / (1024 * 1024)\n",
    "    print(f'  {f.name} ({size_mb:.1f} MB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5: narration points\n",
    "\n",
    "print('\\n' + '='*60)\n",
    "print('NARRATION POINTS FOR DEMO')\n",
    "print('='*60)\n",
    "\n",
    "print('''\n",
    "1. INTRO (0:00-0:10)\n",
    "   - \"This is Bottlejob Detector, a soccer analytics system\"\n",
    "   - \"It tracks players, computes pitch control, and predicts game momentum\"\n",
    "\n",
    "2. EVAL BAR EXPLANATION (first clip)\n",
    "   - \"The eval bar shows which team is dominating\"\n",
    "   - \"Blue = home team advantage, Red = away team advantage\"\n",
    "   - \"Range is -100 to +100\"\n",
    "\n",
    "3. PITCH CONTROL (visible in overlay)\n",
    "   - \"The colored regions show which team controls each area\"\n",
    "   - \"Based on Voronoi diagrams from player positions\"\n",
    "\n",
    "4. MOMENTUM SHIFTS (highlight clips)\n",
    "   - \"Watch the eval bar swing as possession changes\"\n",
    "   - \"Big swings often precede goals or chances\"\n",
    "\n",
    "5. TECHNICAL NOTES\n",
    "   - Player tracking: YOLO + ByteTrack\n",
    "   - Pitch mapping: Keypoint detection + homography\n",
    "   - Eval formula: pitch_control + xT + pressure\n",
    "   - Pass success: logistic regression on distance/angle/defenders\n",
    "''')\n",
    "\n",
    "# eval bar stats for narration\n",
    "print('\\nKEY STATS:')\n",
    "print(f\"  Eval range: {eval_df['eval_bar'].min():.0f} to {eval_df['eval_bar'].max():.0f}\")\n",
    "print(f\"  Mean eval: {eval_df['eval_bar'].mean():.1f}\")\n",
    "print(f\"  Std dev: {eval_df['eval_bar'].std():.1f}\")\n",
    "print(f\"  Big swings (>20 in 10 frames): {(eval_df['eval_change'].rolling(10).sum() > 20).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## verification checklist\n",
    "\n",
    "- [ ] clips are 30-60s each\n",
    "- [ ] eval bar clearly visible in clips\n",
    "- [ ] demo reel plays smoothly\n",
    "- [ ] narration points cover key features"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
