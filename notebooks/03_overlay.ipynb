{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 03 overlay\n",
    "\n",
    "**in**: video, tracking csv, eval_ts, pass_df  \n",
    "**out**: `data/render/final.mp4`\n",
    "\n",
    "overlay stack (bottom to top):\n",
    "1. source frame\n",
    "2. pitch control voronoi (alpha=0.3)\n",
    "3. xT zones (alpha=0.2)\n",
    "4. pass arrows colored by risk\n",
    "5. eval bar gauge (corner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": "# cell 1: load all data\n\nfrom pathlib import Path\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport supervision as sv\nfrom scipy.spatial import Voronoi\nfrom ultralytics import YOLO\n\nfrom sports.common.view import ViewTransformer\nfrom sports.configs.soccer import SoccerPitchConfiguration\n\n# paths\nVIDEO_DIR = Path('../data/video')\nTRACK_DIR = Path('../data/track')\nOUT_DIR = Path('../data/out')\nRENDER_DIR = Path('../data/render')\nMODEL_DIR = Path('../data/models')\nRENDER_DIR.mkdir(parents=True, exist_ok=True)\n\n# find files\nvideo_files = list(VIDEO_DIR.glob('*.mp4'))\nif not video_files:\n    raise FileNotFoundError(f'no video found in {VIDEO_DIR}')\nVIDEO_PATH = video_files[0]\nMATCH_NAME = VIDEO_PATH.stem\n\nTRACK_CSV = TRACK_DIR / f'{MATCH_NAME}_track.csv'\nEVAL_CSV = OUT_DIR / f'{MATCH_NAME}_eval_ts.csv'\nPASS_CSV = OUT_DIR / f'{MATCH_NAME}_pass_df.csv'\n\nprint(f'video: {VIDEO_PATH}')\nprint(f'track: {TRACK_CSV}')\nprint(f'eval: {EVAL_CSV}')\n\n# load data\ntrack_df = pd.read_csv(TRACK_CSV)\neval_df = pd.read_csv(EVAL_CSV)\npass_df = pd.read_csv(PASS_CSV) if PASS_CSV.exists() else pd.DataFrame()\n\nprint(f'track: {len(track_df)} rows')\nprint(f'eval: {len(eval_df)} rows')\nprint(f'passes: {len(pass_df)} rows')\n\n# video info\nvideo_info = sv.VideoInfo.from_video_path(str(VIDEO_PATH))\nFPS = video_info.fps\nWIDTH = video_info.width\nHEIGHT = video_info.height\nprint(f'video: {WIDTH}x{HEIGHT} @ {FPS} fps')\n\n# pitch config (12000x7000 cm = 120x70 m)\nPITCH_CFG = SoccerPitchConfiguration()\nPITCH_X = 120.0  # meters\nPITCH_Y = 70.0   # meters"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 2: draw functions\n",
    "\n",
    "# colors\n",
    "TEAM_COLORS = {\n",
    "    0: (33, 150, 243),   # blue (BGR)\n",
    "    1: (244, 67, 54),    # red\n",
    "    2: (255, 235, 59),   # yellow (goalkeeper)\n",
    "    3: (0, 0, 0),        # black (referee)\n",
    "    4: (255, 255, 255),  # white (ball)\n",
    "}\n",
    "\n",
    "\n",
    "def draw_pitch_control(frame, frame_df, vtf_inv, alpha=0.3):\n",
    "    \"\"\"\n",
    "    Draw pitch control voronoi overlay.\n",
    "    vtf_inv: inverse view transformer (pitch -> pixel)\n",
    "    \"\"\"\n",
    "    overlay = np.zeros_like(frame, dtype=np.uint8)\n",
    "    \n",
    "    players = frame_df[(frame_df['team'].isin([0, 1])) & (frame_df['cls'] == 'player')]\n",
    "    if len(players) < 4:\n",
    "        return frame\n",
    "    \n",
    "    points = players[['x', 'y']].values\n",
    "    teams = players['team'].values\n",
    "    \n",
    "    # add mirror points for bounded voronoi\n",
    "    mirror = []\n",
    "    for p in points:\n",
    "        mirror.append([-p[0], p[1]])\n",
    "        mirror.append([2*PITCH_X - p[0], p[1]])\n",
    "        mirror.append([p[0], -p[1]])\n",
    "        mirror.append([p[0], 2*PITCH_Y - p[1]])\n",
    "    \n",
    "    all_pts = np.vstack([points, mirror])\n",
    "    \n",
    "    try:\n",
    "        vor = Voronoi(all_pts)\n",
    "    except Exception:\n",
    "        return frame\n",
    "    \n",
    "    # draw regions for original points\n",
    "    for i in range(len(points)):\n",
    "        region_idx = vor.point_region[i]\n",
    "        if region_idx == -1:\n",
    "            continue\n",
    "        region = vor.regions[region_idx]\n",
    "        if -1 in region or len(region) < 3:\n",
    "            continue\n",
    "        \n",
    "        # clip polygon to pitch\n",
    "        poly_pitch = vor.vertices[region]\n",
    "        poly_pitch = np.clip(poly_pitch, [0, 0], [PITCH_X, PITCH_Y])\n",
    "        \n",
    "        # transform to pixel coords\n",
    "        if vtf_inv is not None:\n",
    "            poly_pixel = vtf_inv.transform_points(poly_pitch.astype(np.float32))\n",
    "            poly_pixel = poly_pixel.astype(np.int32)\n",
    "            \n",
    "            color = TEAM_COLORS.get(int(teams[i]), (128, 128, 128))\n",
    "            cv2.fillPoly(overlay, [poly_pixel], color)\n",
    "    \n",
    "    # blend\n",
    "    return cv2.addWeighted(frame, 1.0, overlay, alpha, 0)\n",
    "\n",
    "\n",
    "def draw_xt_heat(frame, ball_x, ball_y, vtf_inv, alpha=0.2):\n",
    "    \"\"\"\n",
    "    Draw xT heatmap around ball position.\n",
    "    \"\"\"\n",
    "    if ball_x is None or vtf_inv is None:\n",
    "        return frame\n",
    "    \n",
    "    overlay = np.zeros_like(frame, dtype=np.uint8)\n",
    "    \n",
    "    # create gradient around ball\n",
    "    grid_size = 10\n",
    "    for gx in range(0, int(PITCH_X), grid_size):\n",
    "        for gy in range(0, int(PITCH_Y), grid_size):\n",
    "            cx, cy = gx + grid_size/2, gy + grid_size/2\n",
    "            xt = (cx / PITCH_X) ** 1.8 * np.exp(-((cy - PITCH_Y/2)**2) / (2*18**2))\n",
    "            \n",
    "            # color based on xT (green to red)\n",
    "            r = int(255 * xt)\n",
    "            g = int(255 * (1 - xt))\n",
    "            color = (0, g, r)  # BGR\n",
    "            \n",
    "            # transform corners to pixel\n",
    "            corners = np.array([\n",
    "                [gx, gy], [gx + grid_size, gy],\n",
    "                [gx + grid_size, gy + grid_size], [gx, gy + grid_size]\n",
    "            ], dtype=np.float32)\n",
    "            \n",
    "            try:\n",
    "                pixel_corners = vtf_inv.transform_points(corners).astype(np.int32)\n",
    "                cv2.fillPoly(overlay, [pixel_corners], color)\n",
    "            except Exception:\n",
    "                pass\n",
    "    \n",
    "    return cv2.addWeighted(frame, 1.0, overlay, alpha, 0)\n",
    "\n",
    "\n",
    "def draw_pass_arrows(frame, pass_df, current_frame, vtf_inv, window=30):\n",
    "    \"\"\"\n",
    "    Draw recent pass arrows colored by risk.\n",
    "    \"\"\"\n",
    "    if len(pass_df) == 0 or vtf_inv is None:\n",
    "        return frame\n",
    "    \n",
    "    recent = pass_df[\n",
    "        (pass_df['frame_start'] <= current_frame) & \n",
    "        (pass_df['frame_end'] >= current_frame - window)\n",
    "    ]\n",
    "    \n",
    "    for _, p in recent.iterrows():\n",
    "        start = np.array([[p['sx'], p['sy']]], dtype=np.float32)\n",
    "        end = np.array([[p['ex'], p['ey']]], dtype=np.float32)\n",
    "        \n",
    "        try:\n",
    "            start_px = vtf_inv.transform_points(start)[0].astype(int)\n",
    "            end_px = vtf_inv.transform_points(end)[0].astype(int)\n",
    "        except Exception:\n",
    "            continue\n",
    "        \n",
    "        # color by success probability\n",
    "        p_pass = p.get('p_pass', 0.5)\n",
    "        if p_pass >= 0.72:\n",
    "            color = (0, 255, 0)  # green - safe\n",
    "        elif p_pass >= 0.45:\n",
    "            color = (0, 255, 255)  # yellow - medium\n",
    "        else:\n",
    "            color = (0, 0, 255)  # red - risky\n",
    "        \n",
    "        cv2.arrowedLine(frame, tuple(start_px), tuple(end_px), color, 3, tipLength=0.2)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "def draw_eval_gauge(frame, eval_val, x=50, y=50, w=200, h=30):\n",
    "    \"\"\"\n",
    "    Draw eval bar gauge in corner.\n",
    "    eval_val: -100 to 100\n",
    "    \"\"\"\n",
    "    # background\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (50, 50, 50), -1)\n",
    "    cv2.rectangle(frame, (x, y), (x + w, y + h), (255, 255, 255), 2)\n",
    "    \n",
    "    # center line\n",
    "    cx = x + w // 2\n",
    "    cv2.line(frame, (cx, y), (cx, y + h), (200, 200, 200), 2)\n",
    "    \n",
    "    # fill based on eval\n",
    "    fill_w = int((abs(eval_val) / 100.0) * (w // 2))\n",
    "    \n",
    "    if eval_val >= 0:\n",
    "        color = TEAM_COLORS[0]  # blue\n",
    "        cv2.rectangle(frame, (cx, y + 2), (cx + fill_w, y + h - 2), color, -1)\n",
    "    else:\n",
    "        color = TEAM_COLORS[1]  # red\n",
    "        cv2.rectangle(frame, (cx - fill_w, y + 2), (cx, y + h - 2), color, -1)\n",
    "    \n",
    "    # text\n",
    "    text = f'{int(eval_val):+d}'\n",
    "    cv2.putText(frame, text, (x + w + 10, y + h - 5), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "    cv2.putText(frame, 'EVAL', (x, y - 5), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)\n",
    "    \n",
    "    return frame\n",
    "\n",
    "\n",
    "print('draw functions defined')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "# cell 3: frame-by-frame overlay render\n\n# load pitch keypoint model for view transform\nKP_MODEL_PATH = MODEL_DIR / 'football-pitch-detection.pt'\nkp_model = YOLO(str(KP_MODEL_PATH))\n\n# output video\nOUTPUT_PATH = RENDER_DIR / f'{MATCH_NAME}_overlay.mp4'\nfourcc = cv2.VideoWriter_fourcc(*'mp4v')\nwriter = cv2.VideoWriter(str(OUTPUT_PATH), fourcc, FPS, (WIDTH, HEIGHT))\n\n# create eval lookup\neval_lookup = dict(zip(eval_df['frame'], eval_df['eval_bar']))\n\n# convert pitch config vertices from cm to meters for matching our tracking data\npitch_vertices_m = np.array(PITCH_CFG.vertices) / 100.0  # cm -> m\n\n# render\nframe_idx = 0\nrendered = 0\n\nfor frame in sv.get_video_frames_generator(str(VIDEO_PATH)):\n    # get eval for this frame\n    eval_val = eval_lookup.get(frame_idx, 0)\n    \n    # get tracking data for this frame\n    frame_df = track_df[track_df['frame'] == frame_idx]\n    \n    # get view transform\n    vtf_inv = None\n    try:\n        kp_result = kp_model(frame, verbose=False)[0]\n        kps = sv.KeyPoints.from_ultralytics(kp_result)\n        if len(kps.xy) > 0:\n            mask = (kps.xy[0][:, 0] > 1) & (kps.xy[0][:, 1] > 1)\n            if mask.sum() >= 4:\n                # inverse transform: pitch (meters) -> pixel\n                vtf_inv = ViewTransformer(\n                    source=pitch_vertices_m[mask].astype(np.float32),\n                    target=kps.xy[0][mask].astype(np.float32),\n                )\n    except Exception:\n        pass\n    \n    # apply overlays\n    if len(frame_df) > 0 and vtf_inv is not None:\n        # pitch control (alpha=0.3)\n        frame = draw_pitch_control(frame, frame_df, vtf_inv, alpha=0.25)\n        \n        # xT heat (alpha=0.2) - optional, can be slow\n        # ball = frame_df[frame_df['cls'] == 'ball']\n        # if len(ball) > 0:\n        #     frame = draw_xt_heat(frame, ball['x'].iloc[0], ball['y'].iloc[0], vtf_inv, alpha=0.15)\n        \n        # pass arrows\n        frame = draw_pass_arrows(frame, pass_df, frame_idx, vtf_inv)\n    \n    # eval gauge (always)\n    frame = draw_eval_gauge(frame, eval_val, x=50, y=50)\n    \n    writer.write(frame)\n    rendered += 1\n    frame_idx += 1\n    \n    if frame_idx % 250 == 0:\n        print(f'rendered {frame_idx} frames')\n\nwriter.release()\nprint(f'\\noverlay saved: {OUTPUT_PATH}')\nprint(f'rendered {rendered} frames')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 4: ffmpeg compose with source video\n",
    "\n",
    "import subprocess\n",
    "\n",
    "FINAL_PATH = RENDER_DIR / f'{MATCH_NAME}_final.mp4'\n",
    "\n",
    "# if you want semi-transparent overlay on source:\n",
    "# ffmpeg -y -i src.mp4 -i overlay.mp4 \\\n",
    "#   -filter_complex \"[1:v]format=rgba,colorchannelmixer=aa=0.5[ov];[0:v][ov]overlay\" \\\n",
    "#   -c:v libx264 -crf 20 final.mp4\n",
    "\n",
    "# for now, just copy the overlay (which already has source baked in)\n",
    "cmd = [\n",
    "    'ffmpeg', '-y',\n",
    "    '-i', str(OUTPUT_PATH),\n",
    "    '-c:v', 'libx264',\n",
    "    '-preset', 'fast',\n",
    "    '-crf', '22',\n",
    "    '-pix_fmt', 'yuv420p',\n",
    "    str(FINAL_PATH)\n",
    "]\n",
    "\n",
    "print(f'running: {\" \".join(cmd)}')\n",
    "result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(f'final video: {FINAL_PATH}')\n",
    "else:\n",
    "    print(f'ffmpeg error: {result.stderr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cell 5: export clips\n",
    "\n",
    "def extract_clip(input_path, output_path, start_sec, duration_sec):\n",
    "    \"\"\"Extract a clip from video.\"\"\"\n",
    "    cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-ss', str(start_sec),\n",
    "        '-i', str(input_path),\n",
    "        '-t', str(duration_sec),\n",
    "        '-c:v', 'libx264',\n",
    "        '-preset', 'fast',\n",
    "        '-crf', '22',\n",
    "        str(output_path)\n",
    "    ]\n",
    "    subprocess.run(cmd, capture_output=True)\n",
    "    print(f'clip saved: {output_path}')\n",
    "\n",
    "\n",
    "# find interesting moments (big eval swings)\n",
    "eval_df['eval_change'] = eval_df['eval_bar'].diff().abs()\n",
    "big_swings = eval_df.nlargest(5, 'eval_change')\n",
    "\n",
    "print('biggest eval swings:')\n",
    "print(big_swings[['frame', 't_sec', 'eval_bar', 'eval_change']])\n",
    "\n",
    "# export clips around swings\n",
    "CLIPS_DIR = RENDER_DIR / 'clips'\n",
    "CLIPS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "for i, (_, row) in enumerate(big_swings.iterrows()):\n",
    "    start = max(0, row['t_sec'] - 10)\n",
    "    clip_path = CLIPS_DIR / f'{MATCH_NAME}_highlight_{i+1}.mp4'\n",
    "    extract_clip(FINAL_PATH, clip_path, start, 20)\n",
    "\n",
    "print(f'\\n{len(big_swings)} clips exported to {CLIPS_DIR}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## verification checklist\n",
    "\n",
    "- [ ] overlay renders without crashing\n",
    "- [ ] pitch control visible but not overwhelming\n",
    "- [ ] eval bar gauge updates smoothly\n",
    "- [ ] final.mp4 plays correctly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}